{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код по статье https://pdfs.semanticscholar.org/bb92/da93fb97510c00968255de7f872b8e99fba9.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем нулевой слой - самим признаковым пространством объекта.\n",
    "Т.е. у нас есть один скрытый слой с 5 нейронами и softmax-слой с 3 выходами\n",
    "\n",
    "Обрати внимание на переменную log_prior_initial_value.\n",
    "Это логарифм значения диагональных элементов ковариационной матрицы.\n",
    "\n",
    "В дальнейшем ковариация используется только в логарифмическом виде, т.к. при оптимизации этого параметра \n",
    "\"в тупую\", без логарифма градиент достаточно неустойчивый и может произойти переполнение и выход в NaN.\n",
    "\n",
    "Evidence полагается на распределение параметров, для каждого шага оптимизации полагается сэмплировать параметры.\n",
    "При оптимизации гиперпараметров, шум, который возникает при сэмплировании, может сильно замедлить процесс оптимизации (в то же время, совсем выключать его некорректно по определению Evidence).\n",
    "Поэтому во время оптимизации гиперпараметров предлагается запускать порождать несколько векторов параметров и усреднять их результат. За количество сэмплов отвечает переменная validation_sample_num\n",
    "\n",
    "Для оптимизации гиперпараметров используется градиентный спуск с шагом hyper_learning_rate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "layers = [13, 5, 3] # layer 0  = X matrix\n",
    "iter_num = 4000\n",
    "learning_rate = 0.5\n",
    "log_prior_initial_value = 0.0\n",
    "validation_sample_num = 5\n",
    "hyper_learning_rate= 10**(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 13) (34, 13)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv( \"train.csv\")\n",
    "del train['Unnamed: 0']\n",
    "count_of_train_data = len(train)\n",
    "\n",
    "\n",
    "test = pd.read_csv(  \"test.csv\")\n",
    "del test['Unnamed: 0']\n",
    "\n",
    "Ytrain = train['Type'].as_matrix()\n",
    "Ytrain.reshape([-1])\n",
    "del train['Type']\n",
    "Xtrain = train.as_matrix()\n",
    "\n",
    "Ytest = test['Type'].as_matrix()\n",
    "Ytest.reshape([-1])\n",
    "del test['Type']\n",
    "Xtest = test.as_matrix()\n",
    "print Xtrain.shape, Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "объявление переменных.\n",
    "У нас есть две переменные, отвечающие за вариационное распределение Q:\n",
    "params_mean и log_params_sigma, среднее и отклонение параметров соответственно.\n",
    "\n",
    "Вектора из params_noises --- просто гауссовый шум\n",
    "\n",
    "Также я добавил переменную Noise_on, т.к. при подсчете accuracy имеет смысл выключать шум и учитывать только среднее значение параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float64, [None, Xtrain.shape[1]])\n",
    "Y = tf.placeholder(tf.int32, [None])\n",
    "Noise_on = tf.placeholder(tf.float64, [])\n",
    "\n",
    "param_num = sum([layers[i]*layers[i+1] for i in xrange(0,len(layers)-1)]) + sum(layers[1:]) # Matrices + Biases\n",
    "\n",
    "params_mean = tf.Variable(np.random.rand(param_num)*0.01, dtype=tf.float64, name=\"mean\")\n",
    "log_params_sigma = tf.Variable(np.ones(param_num)*0.01, dtype=tf.float64, name=\"sigma\")\n",
    "params_noises = []\n",
    "for _ in xrange(validation_sample_num):\n",
    "    noise = tf.random_normal([param_num], dtype=tf.float64) \n",
    "    #\n",
    "    params_noises.append(noise)\n",
    "    \n",
    "log_prior_diagonal =  tf.Variable(np.ones(param_num)*log_prior_initial_value, dtype=tf.float64,name='log_prior')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Послойное построение модели.\n",
    "Вынесено как функция, возвращающая выход модели и softmax-правдоподобие.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(noise_id=0, x_tensor=X,y_tensor=Y, means=params_mean, log_sigmas=log_params_sigma):\n",
    "    noise = params_noises[noise_id]\n",
    "    params_noisy = means +  tf.scalar_mul(Noise_on,  tf.multiply(noise, tf.exp(log_sigmas)))\n",
    "    \n",
    "    current_layer = x_tensor\n",
    "    matrix_offset = 0\n",
    "    bias_offset = sum([layers[i]*layers[i+1] for i in xrange(0,len(layers)-1)])\n",
    "    for layer_id in xrange(len(layers)-1):\n",
    "\n",
    "        activation = tf.sigmoid if layer_id < len(layers)-2 else lambda x: x\n",
    "        matrix_params = tf.reshape(params_noisy[matrix_offset:matrix_offset + layers[layer_id]*layers[layer_id+1]],\n",
    "                                   (layers[layer_id], layers[layer_id+1]))\n",
    "        bias_params = params_noisy[bias_offset:bias_offset + layers[layer_id+1]]\n",
    "\n",
    "        matrix_offset+=layers[layer_id]*layers[layer_id+1]\n",
    "        bias_offset+=layers[layer_id+1]\n",
    "        current_layer = activation(tf.matmul(current_layer,matrix_params)+bias_params)\n",
    "    softmax_loss =  tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=y_tensor, logits=current_layer))*Xtrain.shape[0]\n",
    "    return current_layer, softmax_loss\n",
    "\n",
    "network_last_layer, parameters_train_softmax_loss = build()\n",
    "predict = tf.argmax(network_last_layer, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подсчета D_KL имеет смысл использовать стандартную формулу, которая дана в википедии.\n",
    "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Multivariate_normal_distributions\n",
    "\n",
    "Функция потерь состоит из двух слагаемых, первое из которых расчитывается (всегда!) для выборки фиксированного размера. Чтобы использовать мини-батчи нужно взять среднее от софтмакса и домножить на размер выборки.\n",
    "\n",
    "Таким образом, порядок величины будет всегда постоянным вне зависимости от размера батча, и будет корректно соотноситься с размером D_KL.\n",
    "\n",
    "norm_loss --- номировка функции, независимая от размера выборки. Удобна для подбора learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_KL_part0 = tf.reduce_sum(tf.exp(2*log_params_sigma-2*log_prior_diagonal))\n",
    "D_KL_part1 = tf.reduce_sum(tf.multiply(params_mean/tf.exp(2*log_prior_diagonal), (params_mean)))\n",
    "D_KL_part2 = -param_num\n",
    "D_KL_part3 = 2*tf.reduce_sum(log_prior_diagonal) - 2*tf.reduce_sum(log_params_sigma)\n",
    "D_KL = 0.5*(D_KL_part0+D_KL_part1+D_KL_part2+D_KL_part3)\n",
    "loss =parameters_train_softmax_loss+D_KL\n",
    "norm_loss = loss/Xtrain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(norm_loss, var_list=[params_mean, log_params_sigma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея оптимизации гиперпараметров изложена в \n",
    "https://arxiv.org/pdf/1511.06727.pdf\n",
    "\n",
    "Пусть $L$ --- функция потерь, $\\mathbf{w}$ --- параметры, $\\mathbf{h}$ --- гиперпараметры, $\\gamma$ --- длина шага оптимизации,  $\\gamma'$ --- длина шага оптимизации гиперпараметров.\n",
    "\n",
    "1. Считаем градиенты $\\nabla_\\mathbf{w} L(\\mathbf{w})$  (в коде: grads)\n",
    "2. Получаем предсказание новых параметров (оптимизацию мы еще не провели): $\\mathbf{w}' =\\mathbf{w} - \\gamma  \\nabla_\\mathbf{w} L(\\mathbf{w})$ (в коде: new_means, new_sigmas)\n",
    "3. Вычисляем значение функции потерь на предсказанных параметрах   L(\\mathbf{w}') (в коде: full_hyperparameter_optimization_loss)\n",
    "4. Вычисляем градиент гиперпараметров по предсказанным параметрам: $\\mathbf{h}' =\\mathbf{h} - \\gamma  \\nabla_\\mathbf{h} L(\\mathbf{w}')$  (в коде: hyperoptimizer)\n",
    "\n",
    "Как можно видеть, такая оптимизация получается достаточно \"жадной\", т.к. смотрит на один шаг оптимизации вперед. Тем не менее, она показывает достаточно хорошее качество, и не очень сильно тормозит (в сравнении с другими градиентными методами).\n",
    "\n",
    "Тут надо заметить, что в общем случае оптимизации параметров и гиперпараметров на одной выборке и одной функции $L$ является некорректной, т.к. ведет к переобучению. Но конкретно Evidence --- показатель сложности из байесовского вывода, которая как раз должна контролировать переобучение и (в теории), оптимизация гиперпараметров таким способом не должна вести к переобучению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_optimization_loses =[]\n",
    "for noise_id in xrange((validation_sample_num)):\n",
    "    _, softmax_loss = build(noise_id=noise_id)\n",
    "    train_optimization_loses.append(softmax_loss)\n",
    "\n",
    "full_train_optimization_loss = (tf.reduce_mean(train_optimization_loses) + D_KL)/Xtrain.shape[0]\n",
    "grads = tf.gradients(full_train_optimization_loss, [params_mean, log_params_sigma])\n",
    "new_means =params_mean -  tf.scalar_mul(learning_rate,grads[0])\n",
    "new_sigmas =log_params_sigma -   tf.scalar_mul(learning_rate,grads[1])\n",
    "\n",
    "expected_losses_after_training_step = []\n",
    "for noise_id in xrange((validation_sample_num)):\n",
    "    _, softmax_loss = build(noise_id=noise_id, log_sigmas=new_sigmas, means=new_means)\n",
    "    expected_losses_after_training_step.append(softmax_loss/Xtrain.shape[0])\n",
    "    \n",
    "full_hyperparameter_optimization_loss = tf.reduce_mean(expected_losses_after_training_step) + D_KL/Xtrain.shape[0]\n",
    "hyperoptimizer = tf.train.GradientDescentOptimizer(hyper_learning_rate).minimize(full_hyperparameter_optimization_loss, var_list=[log_prior_diagonal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизация. \n",
    "Идет значительно дольше, чем обычно из-за оптимизации гиперпараметров. \n",
    "По идее, можно проводить оптимизацию гиперпараметров не каждый шаг, а каждый K-й шаг.\n",
    "\n",
    "Значение функции ошибки доходит где-то до 0.3, без оптимизации гиперпараметров до 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Negative Evidence Value 1.9481839688009879\n",
      "Current Negative Evidence Value 0.7557273646058338\n",
      "Current Negative Evidence Value 0.5411230352330353\n",
      "Current Negative Evidence Value 0.48835753615763333\n",
      "Current Negative Evidence Value 0.4922345225921691\n",
      "Current Negative Evidence Value 0.4337001289945601\n",
      "Current Negative Evidence Value 0.5557949168636\n",
      "Current Negative Evidence Value 0.4591456285593813\n",
      "Current Negative Evidence Value 0.6194664437487163\n",
      "Current Negative Evidence Value 0.44692480876485174\n",
      "Current Negative Evidence Value 0.45194904770795585\n",
      "Current Negative Evidence Value 0.46458310893187993\n",
      "Current Negative Evidence Value 0.4524801203708402\n",
      "Current Negative Evidence Value 0.4110467912262881\n",
      "Current Negative Evidence Value 0.42566251937192207\n",
      "Current Negative Evidence Value 0.4047440569915696\n",
      "Current Negative Evidence Value 0.4484063962006244\n",
      "Current Negative Evidence Value 0.4748197014640283\n",
      "Current Negative Evidence Value 0.3993890475697701\n",
      "Current Negative Evidence Value 0.43409183854742406\n",
      "Current Negative Evidence Value 0.36132310104639287\n",
      "Current Negative Evidence Value 0.4518098857509756\n",
      "Current Negative Evidence Value 0.3575035754425884\n",
      "Current Negative Evidence Value 0.3584320970458379\n",
      "Current Negative Evidence Value 0.336480683984232\n",
      "Current Negative Evidence Value 0.42967149194708365\n",
      "Current Negative Evidence Value 0.31995720594307653\n",
      "Current Negative Evidence Value 0.32445554573840696\n",
      "Current Negative Evidence Value 0.3547655206839811\n",
      "Current Negative Evidence Value 0.32579461605925014\n",
      "Current Negative Evidence Value 0.4123480957580356\n",
      "Current Negative Evidence Value 0.4025577677936761\n",
      "Current Negative Evidence Value 0.48008196455251134\n",
      "Current Negative Evidence Value 0.3709500833992764\n",
      "Current Negative Evidence Value 0.34034049379865766\n",
      "Current Negative Evidence Value 0.3291761494052888\n",
      "Current Negative Evidence Value 0.31070423938869457\n",
      "Current Negative Evidence Value 0.41121151658466243\n",
      "Current Negative Evidence Value 0.30043910024992343\n",
      "Current Negative Evidence Value 0.30859567535557386\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(Xtrain.shape[0])\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "# Train\n",
    "for iter_id in range(iter_num):\n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "    batch_xs, batch_ys = Xtrain[indices[:batch_size]], Ytrain[indices[:batch_size]]\n",
    "    sess.run(optimizer, feed_dict={X: batch_xs, Y: batch_ys, Noise_on:1.0})\n",
    "    sess.run(hyperoptimizer, feed_dict={X: batch_xs, Y: batch_ys, Noise_on:1.0})\n",
    "    if iter_id %100 ==0:\n",
    "        print 'Current Negative Evidence Value', sess.run(full_train_optimization_loss, feed_dict={X: batch_xs, Y: batch_ys, Noise_on:1.0})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4509462   0.01296022  0.08429638 -0.08091552  0.09055842 -0.14402647\n",
      " -0.01456625 -0.10137628 -0.10559321 -0.06692522  0.2066911  -0.00784687\n",
      " -0.06007069 -0.11388554 -0.03169651 -0.01506439 -0.01697802  0.09204491\n",
      " -0.02108706  0.0640696  -0.19930579 -0.02369662 -0.06997823 -0.08355656\n",
      " -0.05125187 -0.19653902 -0.02423523 -0.00906923  0.00270837 -0.00625812\n",
      " -0.06144586  0.01673632  0.12002873  0.25201568  0.06263161 -0.20595645\n",
      " -0.03814632 -0.07983597 -0.06905319 -0.06434454 -0.11983108 -0.00813991\n",
      " -0.08101347 -0.0508759  -0.05239741  0.32555478  0.03759225 -0.09361003\n",
      "  0.04706109 -0.04736552  0.30055063  0.04189746 -0.06410321  0.11112653\n",
      " -0.04687927 -0.18841861  0.01526692  0.09517976  0.23541169  0.05291239\n",
      "  0.50607412 -0.01085597  0.29465138 -0.01775956  0.18549391  0.08066453\n",
      "  1.44665529  0.23569962 -0.16246324 -0.10662447 -0.04578853  0.57052132\n",
      " -0.07764675  0.04079004  0.3718553  -0.151086    0.80460069  0.23295472\n",
      " -0.08558622 -0.06288857  0.13552853 -0.02228213 -0.03952764 -0.04275452\n",
      " -0.03584301 -0.1729281  -0.15737071 -0.16848214]\n"
     ]
    }
   ],
   "source": [
    "print log_prior_diagonal.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:train 1.0\n",
      "Accuracy:test 0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "predicted_train = sess.run(predict, feed_dict={X:Xtrain, Noise_on:0.0}) \n",
    "predicted_test = sess.run(predict, feed_dict={X:Xtest, Noise_on:0.0}) \n",
    "print 'Accuracy:train', np.mean(np.equal(predicted_train, Ytrain))\n",
    "print 'Accuracy:test', np.mean(np.equal(predicted_test, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сортируем по $\\lambda$ и удаляем наименьшие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.argsort(np.abs( params_mean.eval()/np.exp(log_params_sigma.eval())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = []\n",
    "acc_test = []\n",
    "for percent in xrange(0, 101, 5):\n",
    "    _params = params_mean.eval()\n",
    "    null_count = len(_params)*percent/100\n",
    "    _params[lambdas[:null_count]] = 0\n",
    "    sess.run(params_mean.assign(_params))\n",
    "    acc_train.append( np.mean(np.equal(Ytrain, sess.run(predict, feed_dict={X:Xtrain, Noise_on:0.0}) )))\n",
    "    acc_test.append( np.mean(np.equal(Ytest, sess.run(predict, feed_dict={X:Xtest, Noise_on:0.0}) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.plot(range(0, 101, 5), acc_train, label='Train')\n",
    "plt.plot(range(0, 101, 5),acc_test, label='Test')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('% of deleted params')\n",
    "_= plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
